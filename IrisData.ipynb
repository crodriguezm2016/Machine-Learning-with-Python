{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Iris Flower Data Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%tensoryflow_version 2.x"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UsageError: Line magic function `%tensoryflow_version` not found.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth','Species']\r\n",
    "SPECIES = ['Setosa','Versicolor', 'Virginica']\r\n",
    "# Defining constants to use later"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_path = tf.keras.utils.get_file(\r\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\r\n",
    "test_path = tf.keras.utils.get_file(\r\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\r\n",
    "\r\n",
    "train = pd.read_csv(train_path, names = CSV_COLUMN_NAMES, header=0)\r\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# train.head()\r\n",
    "\r\n",
    "train_y = train.pop('Species')\r\n",
    "test_y = test.pop('Species')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\r\n",
    "    # Convert the inputs to a dataset\r\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\r\n",
    "\r\n",
    "    #Shuffle and repeat if you are in training mode.\r\n",
    "    if training:\r\n",
    "        dataset = dataset.shuffle(1000).repeat()\r\n",
    "    return dataset.batch(batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "my_feature_columns = []\r\n",
    "for key in train.keys():\r\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "classifier = tf.estimator.DNNClassifier(\r\n",
    "    feature_columns=my_feature_columns,\r\n",
    "    #two hidden layers of 30 and 10 nodes respectively\r\n",
    "    hidden_units=[30, 10],\r\n",
    "    #model chooses between 3 classes\r\n",
    "    n_classes=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\crodr\\AppData\\Local\\Temp\\tmpp1l8pzi3\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\crodr\\\\AppData\\\\Local\\\\Temp\\\\tmpp1l8pzi3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classifier.train(\r\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\r\n",
    "    steps=5000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\r\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-08-15T16:50:00\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\crodr\\AppData\\Local\\Temp\\tmpp1l8pzi3\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.73854s\n",
      "INFO:tensorflow:Finished evaluation at 2021-08-15-16:50:01\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9, average_loss = 0.5061514, global_step = 5000, loss = 0.5061514\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\crodr\\AppData\\Local\\Temp\\tmpp1l8pzi3\\model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.900\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def input_fn(features, batch_size=256):\r\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\r\n",
    "\r\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\r\n",
    "predict = {}\r\n",
    "\r\n",
    "print(\"Please type numeric values as prompted.\")\r\n",
    "for feature in features:\r\n",
    "    valid = True\r\n",
    "    while valid:\r\n",
    "        val = input(feature + \": \")\r\n",
    "        if not val.isdigit(): valid = False\r\n",
    "    \r\n",
    "    predict[feature] = [float(val)]\r\n",
    "\r\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\r\n",
    "for pred_dict in predictions:\r\n",
    "    class_id = pred_dict['class_ids'][0]\r\n",
    "    probability = pred_dict['probabilities'][class_id]\r\n",
    "\r\n",
    "    print('Preditction is \"{}\" ({:.1f}%)'.format(\r\n",
    "        SPECIES[class_id], 100 * probability))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Please type numeric values as prompted.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\crodr\\AppData\\Local\\Temp\\tmpp1l8pzi3\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Preditction is \"Virginica\" (93.8%)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b003d8754f68205f230b91d29752a0899194161977d5c87b83f80e078894fa96"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}